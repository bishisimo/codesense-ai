"""
ReviewService - ä½¿ç”¨æ–°çš„AIå®¡æŸ¥å™¨æ¶æ„
"""
from typing import Dict, List, Optional, Any
from sqlalchemy import select, delete
from sqlalchemy.ext.asyncio import AsyncSession
import re

from app.core.config import settings
from app.models import MergeRequest, CodeReview, ReviewComment, Project, AIModel, TokenUsage
from app.libs.ai_models import get_model_definition
from app.libs.gitlabx import GitLabClient
from app.libs.gitx import GitError
from app.services.git import GitService
from app.services.review.ai_reviewer import AIReviewer
from app.services.review.ai_interfaces import ReviewRequest, ContextInfo
from app.libs.file_filter import get_file_filter
from app.core.logging import get_logger

logger = get_logger("review_service")


class ReviewService:
    """ä»£ç å®¡æŸ¥æœåŠ¡ - ä½¿ç”¨æ–°çš„AIå®¡æŸ¥å™¨æ¶æ„"""

    def __init__(self, repo_path: str = None):
        self._gitlab_client = None
        self._ai_reviewer = None
        self._git_service = None
        self._repo_path = repo_path
    
    @property
    def gitlab_client(self):
        """å»¶è¿Ÿåˆå§‹åŒ–GitLabå®¢æˆ·ç«¯"""
        if self._gitlab_client is None:
            self._gitlab_client = GitLabClient(
                url=settings.GITLAB_URL,
                token=settings.GITLAB_TOKEN
            )
        return self._gitlab_client
    
    @property
    def ai_reviewer(self):
        """å»¶è¿Ÿåˆå§‹åŒ–AIå®¡æŸ¥å™¨"""
        if self._ai_reviewer is None:
            self._ai_reviewer = AIReviewer()
        return self._ai_reviewer
    
    @property
    def git_service(self):
        """å»¶è¿Ÿåˆå§‹åŒ–GitæœåŠ¡"""
        if self._git_service is None and self._repo_path:
            self._git_service = GitService(self._repo_path)
        return self._git_service

    async def review_merge_request(
            self,
            session: AsyncSession,
            merge_request: MergeRequest,
            force_refresh: bool = False,
            review_type: str = "standard",
            template_name: Optional[str] = None,
            template_id: Optional[int] = None,
            custom_instructions: str = ""
    ) -> Optional[CodeReview]:
        """å®¡æŸ¥åˆå¹¶è¯·æ±‚ - ç»Ÿä¸€å…¥å£æ–¹æ³•
        
        Args:
            session: æ•°æ®åº“ä¼šè¯
            merge_request: åˆå¹¶è¯·æ±‚å¯¹è±¡
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            review_type: å®¡æŸ¥ç±»å‹ ("standard" | "enhanced")
        """
        try:
            # è·å–é¡¹ç›®ä¿¡æ¯
            project = await session.get(Project, merge_request.project_id)
            if not project:
                raise ValueError(f"Project not found: {merge_request.project_id}")

            # ä½¿ç”¨MRè¡¨ä¸­çš„æœ€æ–°commit shaï¼Œè€Œä¸æ˜¯ä»GitLab APIè·å–
            if not merge_request.last_commit_sha:
                raise ValueError("MRæ²¡æœ‰æœ€æ–°çš„commit shaä¿¡æ¯ï¼Œè¯·å…ˆåŒæ­¥MRæ•°æ®")

            commit_sha = merge_request.last_commit_sha

            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å®¡æŸ¥ä¸­çš„è®°å½•
            pending_review = await session.scalar(
                select(CodeReview).where(
                    CodeReview.merge_request_id == merge_request.id,
                    CodeReview.status == "pending"
                )
            )

            if pending_review and not force_refresh:
                logger.info(f"MR {merge_request.id} å·²æœ‰å®¡æŸ¥ä¸­çš„è®°å½•ï¼Œè·³è¿‡é‡å¤å®¡æŸ¥")
                return pending_review

            # æ£€æŸ¥æ˜¯å¦å·²ç»å¯¹æ­¤æäº¤è¿›è¡Œè¿‡å®¡æŸ¥
            existing_review = await session.scalar(
                select(CodeReview).where(
                    CodeReview.merge_request_id == merge_request.id,
                    CodeReview.commit_sha == commit_sha,
                    CodeReview.status == "completed"
                )
            )

            # åªæœ‰åœ¨æœ‰pendingè®°å½•æ—¶æ‰éœ€è¦forceå‚æ•°ï¼Œcompletedè®°å½•ä¸å½±å“æ–°çš„å®¡æŸ¥
            if existing_review and force_refresh:
                # åˆ é™¤ç°æœ‰å®¡æŸ¥å’Œè¯„è®º
                await session.execute(
                    delete(ReviewComment).where(ReviewComment.review_id == existing_review.id)
                )
                await session.delete(existing_review)
                await session.flush()

            # å¦‚æœæœ‰å®¡æŸ¥ä¸­çš„è®°å½•ä¸”å¼ºåˆ¶åˆ·æ–°ï¼Œåˆ é™¤å®ƒ
            if pending_review and force_refresh:
                await session.execute(
                    delete(ReviewComment).where(ReviewComment.review_id == pending_review.id)
                )
                await session.delete(pending_review)
                await session.flush()

            # åˆ›å»ºæ–°çš„å®¡æŸ¥è®°å½•
            review = CodeReview(
                merge_request_id=merge_request.id,
                commit_sha=commit_sha,
                reviewer_type="",  # å°†åœ¨AIå®¡æŸ¥å®Œæˆåè®¾ç½®å®é™…æ¨¡å‹åç§°
                status="pending"
            )
            session.add(review)
            await session.flush()

            # å…ˆæäº¤pendingçŠ¶æ€åˆ°æ•°æ®åº“
            await session.commit()

            # å¼‚æ­¥æ‰§è¡ŒAIå®¡æŸ¥
            import asyncio
            asyncio.create_task(self._async_review_process(
                review.id, project.id, merge_request.id, commit_sha, review_type, template_name, template_id, custom_instructions
            ))

            logger.info(f"AI review started for MR {merge_request.id} (type: {review_type}, commit: {commit_sha})")
            return review

        except Exception as e:
            await session.rollback()

            # æ›´æ–°å®¡æŸ¥çŠ¶æ€ä¸ºå¤±è´¥
            if 'review' in locals():
                try:
                    review.status = "failed"
                    review.error_message = str(e)
                    review.review_content = f"å®¡æŸ¥å¤±è´¥: {str(e)}"
                    
                    # å°è¯•ä¸ºå¤±è´¥çš„å®¡æŸ¥åˆ›å»ºtokenä½¿ç”¨è®°å½•
                    try:
                        await self._create_failed_token_usage_record(session, review, e)
                    except Exception as token_error:
                        logger.error(f"Failed to create token usage record for failed review: {token_error}")
                    
                    await session.commit()
                except Exception as commit_error:
                    logger.error(f"Failed to update review status: {commit_error}")

            import traceback
            logger.error(f"Code review failed: {str(e)}")
            logger.debug(f"Traceback: {traceback.format_exc()}")
            raise e

    async def enhanced_review_merge_request(
            self,
            session: AsyncSession,
            merge_request: MergeRequest,
            repo_path: str,
            force_refresh: bool = False
    ) -> Optional[CodeReview]:
        """å¢å¼ºå®¡æŸ¥åˆå¹¶è¯·æ±‚ - å¤ç”¨æ ‡å‡†å®¡æŸ¥æ–¹æ³•"""
        # ç¡®ä¿GitæœåŠ¡å·²åˆå§‹åŒ–
        if not self._repo_path:
            self._repo_path = repo_path
        
        # éªŒè¯ä»“åº“çŠ¶æ€
        repo_validation = self.git_service.validate_repository()
        if not repo_validation["is_valid"]:
            raise ValueError(f"ä»“åº“éªŒè¯å¤±è´¥: {repo_validation.get('error', 'Unknown error')}")

        # å¤ç”¨æ ‡å‡†å®¡æŸ¥æ–¹æ³•ï¼Œä¼ å…¥enhancedç±»å‹
        return await self.review_merge_request(
            session=session,
            merge_request=merge_request,
            force_refresh=force_refresh,
            review_type="enhanced"
        )

    async def _async_review_process(
            self,
            review_id: int,
            project_id: int,
            merge_request_id: int,
            commit_sha: str,
            review_type: str = "standard",
            template_name: Optional[str] = None,
            template_id: Optional[int] = None,
            custom_instructions: str = ""
    ):
        """å¼‚æ­¥æ‰§è¡ŒAIå®¡æŸ¥è¿‡ç¨‹"""
        from app.core.database import AsyncSessionLocal
        async with AsyncSessionLocal() as new_session:
            try:
                # é‡æ–°è·å–reviewå¯¹è±¡
                review = await new_session.get(CodeReview, review_id)
                if not review:
                    logger.error(f"Review {review_id} not found in async process")
                    return
                
                # é‡æ–°è·å–projectå’Œmerge_requestå¯¹è±¡
                project = await new_session.get(Project, project_id)
                merge_request = await new_session.get(MergeRequest, merge_request_id)
                
                if not project or not merge_request:
                    logger.error(f"Project {project_id} or MergeRequest {merge_request_id} not found in async process")
                    return

                # æ„å»ºAIå®¡æŸ¥ä¸Šä¸‹æ–‡
                context = await self._build_ai_context(
                    new_session, project, merge_request, commit_sha, review_type
                )

                # è·å–ä»£ç å·®å¼‚
                code_diff = await self._get_code_diff(project, merge_request, commit_sha, review_type)
                if not code_diff.strip():
                    raise ValueError("ä»£ç å·®å¼‚ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå®¡æŸ¥")

                logger.info(f"Starting {review_type} AI review for MR {merge_request.id} (commit: {commit_sha})")
                logger.debug(f"Code diff length: {len(code_diff)} characters")

                # è·å–æŒ‡å®šæ¨¡æ¿æˆ–ä½¿ç”¨é»˜è®¤æ¨¡æ¿
                template = None
                if template_name:
                    template = await self.ai_reviewer.get_template_by_name(template_name)
                    if not template:
                        logger.warning(f"æŒ‡å®šçš„æ¨¡æ¿ '{template_name}' ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")
                
                # åˆ›å»ºå®¡æŸ¥è¯·æ±‚ï¼Œå°†è‡ªå®šä¹‰æŒ‡ä»¤æ·»åŠ åˆ°contextä¸­
                if custom_instructions:
                    # å°†è‡ªå®šä¹‰æŒ‡ä»¤æ·»åŠ åˆ°contextä¸­ï¼Œä¾›æ¨¡æ¿æ¸²æŸ“å™¨ä½¿ç”¨
                    context.custom_instructions = custom_instructions

                # åˆ›å»ºå®¡æŸ¥è¯·æ±‚
                review_request = ReviewRequest(
                    code_diff=code_diff,
                    context=context,
                    template=template
                )

                # æ‰§è¡ŒAIå®¡æŸ¥
                review_result = await self.ai_reviewer.review(review_request)

                # éªŒè¯å®¡æŸ¥ç»“æœ
                if not review_result:
                    raise ValueError("AIå®¡æŸ¥è¿”å›ç©ºç»“æœ")

                # å¤„ç†å®¡æŸ¥ç»“æœ
                await self._process_review_result(
                    new_session, review, review_result, context, review_type
                )

                logger.info(f"{review_type.capitalize()} AI review completed for MR {merge_request.id} with score {review.score}")

            except Exception as e:
                await new_session.rollback()

                # æ›´æ–°å®¡æŸ¥çŠ¶æ€ä¸ºå¤±è´¥
                try:
                    # é‡æ–°è·å–reviewå¯¹è±¡ä»¥ç¡®ä¿åœ¨å½“å‰ä¼šè¯ä¸­
                    failed_review = await new_session.get(CodeReview, review_id)
                    if failed_review:
                        failed_review.status = "failed"
                        failed_review.error_message = str(e)
                        failed_review.review_content = f"AIå®¡æŸ¥å¤±è´¥: {str(e)}"
                        
                        # å°è¯•ä¸ºå¤±è´¥çš„å®¡æŸ¥åˆ›å»ºtokenä½¿ç”¨è®°å½•
                        try:
                            await self._create_failed_token_usage_record(new_session, failed_review, e)
                        except Exception as token_error:
                            logger.error(f"Failed to create token usage record for failed review: {token_error}")
                        
                        await new_session.commit()
                        logger.info(f"Review {review_id} status updated to failed")
                    else:
                        logger.error(f"Failed to find review {review_id} for status update")
                except Exception as commit_error:
                    logger.error(f"Failed to update review status: {commit_error}")

                import traceback
                logger.error(f"Async code review failed: {str(e)}")
                logger.debug(f"Traceback: {traceback.format_exc()}")

    async def _build_ai_context(
            self,
            session: AsyncSession,
            project: Project,
            merge_request: MergeRequest,
            commit_sha: str,
            review_type: str
    ) -> ContextInfo:
        """æ„å»ºAIå®¡æŸ¥ä¸Šä¸‹æ–‡"""
        # æ„å»ºåŸºç¡€ä¸Šä¸‹æ–‡
        context = await self.ai_reviewer.context_builder.build_context(
            merge_request, project, commit_sha, review_type
        )

        # å¢å¼ºå®¡æŸ¥ç±»å‹éœ€è¦é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        if review_type == "enhanced" and self.git_service:
            try:
                context = await self.ai_reviewer.context_builder.build_enhanced_context(
                    context, self.git_service
                )
                logger.info(f"Enhanced context built: complexity={context.complexity_analysis.get('complexity_level', 'unknown') if context.complexity_analysis else 'unknown'}")
            except Exception as e:
                logger.warning(f"Failed to build enhanced context: {str(e)}")
                # é™çº§åˆ°æ ‡å‡†ä¸Šä¸‹æ–‡

        return context

    async def _get_code_diff(
            self,
            project: Project,
            merge_request: MergeRequest,
            commit_sha: str,
            review_type: str
    ) -> str:
        """è·å–ä»£ç å·®å¼‚"""
        try:
            # å¢å¼ºå®¡æŸ¥ä¼˜å…ˆä½¿ç”¨gitx
            if review_type == "enhanced" and self.git_service:
                try:
                    diff_info = self.git_service.get_commit_changes(commit_sha)
                    return self._build_diff_from_gitx(diff_info, project)
                except GitError as e:
                    logger.warning(f"GitXè·å–å·®å¼‚å¤±è´¥ï¼Œé™çº§åˆ°GitLab API: {str(e)}")

            # é™çº§åˆ°GitLab API
            changes = self.gitlab_client.get_merge_request_changes(
                project.gitlab_id, merge_request.gitlab_id
            )

            if not changes:
                raise ValueError("æ— æ³•è·å–åˆå¹¶è¯·æ±‚çš„ä»£ç å˜æ›´")

            return self._build_diff_text(changes, project)

        except Exception as e:
            raise ValueError(f"è·å–ä»£ç å·®å¼‚å¤±è´¥: {str(e)}")

    async def _process_review_result(
            self,
            session: AsyncSession,
            review: CodeReview,
            review_result: Any,
            context: ContextInfo,
            review_type: str
    ):
        """å¤„ç†å®¡æŸ¥ç»“æœ"""
        try:
            # åŸºç¡€è¯„åˆ†
            base_score = review_result.score
            
            # å¢å¼ºå®¡æŸ¥éœ€è¦é¢å¤–çš„è¯„åˆ†å¤„ç†
            if review_type == "enhanced":
                complexity_analysis = context.complexity_analysis
                if complexity_analysis:
                    enhanced_score = self._calculate_enhanced_score(base_score, complexity_analysis)
                    enhanced_score = await self._avoid_duplicate_score(session, review.merge_request_id, enhanced_score)
                    final_score = enhanced_score
                else:
                    final_score = base_score
            else:
                final_score = base_score

            # æ›´æ–°å®¡æŸ¥ç»“æœ
            review.score = final_score
            review.score_details = review_result.score_details
            review.review_content = self._build_review_markdown(
                review_result, 
                context.complexity_analysis,
                context.commit_statistics
            )
            review.code_suggestion = self._build_code_suggestions(review_result)
            
            # è®¾ç½®é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(review_result, 'error_message') and review_result.error_message:
                review.error_message = review_result.error_message
            
            # è®¾ç½®å®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
            if hasattr(review_result, 'model_used') and review_result.model_used:
                review.reviewer_type = review_result.model_used
            else:
                # å¦‚æœæ²¡æœ‰æ¨¡å‹ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                default_config = self.ai_reviewer.get_default_model_config()
                review.reviewer_type = f"{default_config.provider.value}/{default_config.model_name}"
            
            # æ ¹æ®åˆ†æ•°åˆ¤æ–­å®¡æŸ¥çŠ¶æ€ï¼šåˆ†æ•°ä¸º0è¡¨ç¤ºå®¡æŸ¥å¤±è´¥
            if final_score == 0:
                review.status = "failed"
                review.error_message = "å®¡æŸ¥å¤±è´¥ï¼šè¯„åˆ†ä¸º0"
                logger.warning(f"Review failed for MR {review.merge_request_id} due to score 0")
            else:
                review.status = "completed"
            
            # åˆ›å»ºTokenUsageè®°å½•
            try:
                await self._create_token_usage_record(session, review, review_result)
            except Exception as e:
                logger.error(f"Failed to create token usage record: {str(e)}")

            # åˆ›å»ºå®¡æŸ¥è¯„è®º
            try:
                await self._create_review_comments(session, review, review_result)
            except Exception as e:
                logger.error(f"Failed to create review comments: {str(e)}")

            await session.commit()

            # å‘é€é€šçŸ¥
            try:
                merge_request = await session.get(MergeRequest, review.merge_request_id)
                if merge_request:
                    project = await session.get(Project, merge_request.project_id)
                    await self._send_notifications(merge_request, review, project)
                else:
                    logger.error(f"Merge request not found for review {review.id}")
            except Exception as e:
                logger.error(f"Failed to send notifications: {str(e)}")
                
        except Exception as e:
            # å¦‚æœå¤„ç†å®¡æŸ¥ç»“æœæ—¶å‡ºç°å¼‚å¸¸ï¼Œå°†çŠ¶æ€è®¾ç½®ä¸ºå¤±è´¥
            logger.error(f"Failed to process review result: {str(e)}")
            review.status = "failed"
            review.error_message = str(e)
            review.review_content = f"å¤„ç†å®¡æŸ¥ç»“æœå¤±è´¥: {str(e)}"
            
            # å°è¯•ä¸ºå¤±è´¥çš„å®¡æŸ¥åˆ›å»ºtokenä½¿ç”¨è®°å½•
            try:
                await self._create_failed_token_usage_record(session, review, e)
            except Exception as token_error:
                logger.error(f"Failed to create token usage record for failed review result: {token_error}")
            
            try:
                await session.commit()
            except Exception as commit_error:
                logger.error(f"Failed to commit failed status: {commit_error}")
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚æ–¹æ³•å¤„ç†
    
    def _build_code_suggestions(self, review_result: Any) -> str:
        """æ„å»ºä»£ç ä¿®æ”¹å»ºè®®"""
        try:
            suggestions = []
            
            # ä»issuesä¸­æå–å»ºè®®
            if hasattr(review_result, 'issues') and review_result.issues:
                for issue in review_result.issues:
                    if isinstance(issue, dict) and issue.get('suggestion'):
                        file_info = f"**æ–‡ä»¶**: {issue.get('file', 'æœªçŸ¥æ–‡ä»¶')}"
                        if issue.get('line'):
                            file_info += f" (ç¬¬{issue['line']}è¡Œ)"
                        
                        suggestion_text = f"""
## {issue.get('title', 'ä»£ç å»ºè®®')}

{file_info}

**é—®é¢˜æè¿°**: {issue.get('description', '')}

**ä¿®æ”¹å»ºè®®**: {issue.get('suggestion', '')}

**ä¸¥é‡ç¨‹åº¦**: {issue.get('severity', 'medium')}
"""
                        suggestions.append(suggestion_text)
            
            # ä»improvementsä¸­æå–å»ºè®®ï¼ˆå‘åå…¼å®¹ï¼‰
            if hasattr(review_result, 'improvements') and review_result.improvements:
                for improvement in review_result.improvements:
                    if improvement:
                        suggestions.append(f"- {improvement}")
            
            if suggestions:
                return "\n\n".join(suggestions)
            else:
                return "æš‚æ— å…·ä½“çš„ä»£ç ä¿®æ”¹å»ºè®®"
                
        except Exception as e:
            logger.error(f"æ„å»ºä»£ç å»ºè®®å¤±è´¥: {str(e)}")
            return f"æ„å»ºä»£ç å»ºè®®å¤±è´¥: {str(e)}"

    def _calculate_enhanced_score(self, base_score: int, complexity_analysis: Dict[str, Any]) -> int:
        """æ ¹æ®å¤æ‚åº¦åˆ†æè®¡ç®—å¢å¼ºè¯„åˆ†"""
        import random

        enhanced_score = base_score

        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´è¯„åˆ†
        complexity_level = complexity_analysis.get("complexity_level", "medium")
        if complexity_level == "very_high":
            enhanced_score -= random.randint(8, 12)
        elif complexity_level == "high":
            enhanced_score -= random.randint(3, 7)
        elif complexity_level == "very_low":
            enhanced_score += random.randint(3, 7)

        # æ ¹æ®å˜æ›´è§„æ¨¡è°ƒæ•´
        total_changes = complexity_analysis.get("total_lines_changed", 0)
        if total_changes > 1000:
            enhanced_score -= random.randint(3, 7)
        elif total_changes < 50:
            enhanced_score += random.randint(2, 5)

        # äºŒè¿›åˆ¶æ–‡ä»¶æƒ©ç½š
        if complexity_analysis.get("binary_files"):
            enhanced_score -= random.randint(1, 3)

        # æ·»åŠ å¾®å°çš„éšæœºæ€§ï¼Œé¿å…è¯„åˆ†è¿‡äºä¸€è‡´
        random_adjustment = random.randint(-2, 2)
        enhanced_score += random_adjustment

        # ç¡®ä¿è¯„åˆ†åœ¨åˆç†èŒƒå›´å†…
        return max(0, min(100, enhanced_score))

    async def _avoid_duplicate_score(self, session: AsyncSession, merge_request_id: int, score: int) -> int:
        """é¿å…é‡å¤è¯„åˆ†ï¼Œå¦‚æœå‘ç°ç›¸åŒè¯„åˆ†åˆ™è¿›è¡Œå¾®è°ƒ"""
        import random

        # æŸ¥è¯¢è¯¥MRçš„å†å²è¯„åˆ†
        result = await session.execute(
            select(CodeReview.score)
            .where(
                CodeReview.merge_request_id == merge_request_id,
                CodeReview.score.isnot(None)
            )
        )

        existing_scores = [row[0] for row in result.fetchall()]

        # å¦‚æœå‘ç°ç›¸åŒè¯„åˆ†ï¼Œè¿›è¡Œå¾®è°ƒ
        if score in existing_scores:
            # åœ¨Â±3åˆ†èŒƒå›´å†…éšæœºè°ƒæ•´ï¼Œä½†é¿å…ä¸ç°æœ‰è¯„åˆ†é‡å¤
            for _ in range(10):  # æœ€å¤šå°è¯•10æ¬¡
                adjustment = random.randint(-3, 3)
                new_score = score + adjustment
                if new_score not in existing_scores and 0 <= new_score <= 100:
                    logger.info(f"æ£€æµ‹åˆ°é‡å¤è¯„åˆ† {score}ï¼Œè°ƒæ•´ä¸º {new_score}")
                    return new_score

            # å¦‚æœæ— æ³•é¿å…é‡å¤ï¼Œè‡³å°‘ç¡®ä¿ä¸å®Œå…¨ç›¸åŒ
            adjustment = random.choice([-1, 1])
            new_score = max(0, min(100, score + adjustment))
            logger.info(f"æ— æ³•é¿å…é‡å¤è¯„åˆ†ï¼Œè¿›è¡Œæœ€å°è°ƒæ•´: {score} -> {new_score}")
            return new_score

        return score

    def _build_review_markdown(
            self,
            review_result: Any,
            complexity_analysis: Dict[str, Any] = None,
            commit_stats: Dict[str, Any] = None
    ) -> str:
        """æ„å»ºMarkdownæ ¼å¼çš„å®¡æŸ¥æŠ¥å‘Š"""
        title = "ä»£ç å®¡æŸ¥æŠ¥å‘Š"

        markdown_parts = [
            f"# {title}",
            f"",
            f"**è¯„åˆ†**: {review_result.score}",
            f"",
        ]

        # æ·»åŠ å®¡æŸ¥çº§åˆ«ï¼ˆæ–°æ ¼å¼ï¼‰
        if hasattr(review_result, 'level') and review_result.level:
            markdown_parts.extend([
                f"**å®¡æŸ¥çº§åˆ«**: {review_result.level}",
                f"",
            ])

        # æ·»åŠ å®¡æŸ¥æ€»ç»“ï¼ˆæ–°æ ¼å¼ï¼‰
        if hasattr(review_result, 'summary') and review_result.summary:
            markdown_parts.extend([
                f"**å®¡æŸ¥æ€»ç»“**: {review_result.summary}",
                f"",
            ])

        # æ·»åŠ è¯¦ç»†è¯„åˆ†
        score_details = None
        if hasattr(review_result, 'categories') and review_result.categories:
            # æ–°æ ¼å¼ï¼šä»categoriesæ„å»ºscore_details
            score_details = {}
            for category in review_result.categories:
                if category.get('name') == 'ä»£ç è´¨é‡':
                    score_details['code_quality'] = {
                        'score': category.get('score', 0),
                        'reason': category.get('description', '')
                    }
                elif category.get('name') == 'åŠŸèƒ½æ­£ç¡®æ€§':
                    score_details['correctness'] = {
                        'score': category.get('score', 0),
                        'reason': category.get('description', '')
                    }
                elif category.get('name') == 'æ€§èƒ½ä¼˜åŒ–':
                    score_details['performance'] = {
                        'score': category.get('score', 0),
                        'reason': category.get('description', '')
                    }
                elif category.get('name') == 'å®‰å…¨æ€§':
                    score_details['security'] = {
                        'score': category.get('score', 0),
                        'reason': category.get('description', '')
                    }
                elif category.get('name') == 'æµ‹è¯•è¦†ç›–':
                    score_details['testing'] = {
                        'score': category.get('score', 0),
                        'reason': category.get('description', '')
                    }
        else:
            # æ—§æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨score_details
            score_details = getattr(review_result, 'score_details', {})

        if score_details:
            markdown_parts.extend([
                "## ğŸ“ˆ è¯¦ç»†è¯„åˆ†",
                "",
                "| è¯„åˆ†ç»´åº¦ | å¾—åˆ† | æ¯”é‡ | è¯„åˆ†åŸå›  |",
                "|:--------|:----:|:----:|:--------|",
            ])

            # å®šä¹‰ç»´åº¦æƒé‡
            weights = {
                "code_quality": {"name": "ä»£ç è´¨é‡", "weight": 30},
                "correctness": {"name": "åŠŸèƒ½æ­£ç¡®æ€§", "weight": 25},
                "performance": {"name": "æ€§èƒ½ä¼˜åŒ–", "weight": 20},
                "security": {"name": "å®‰å…¨æ€§", "weight": 15},
                "testing": {"name": "æµ‹è¯•è¦†ç›–", "weight": 10}
            }

            for dimension, config in weights.items():
                detail = score_details.get(dimension, {})
                if isinstance(detail, dict):
                    score = detail.get("score", 0)
                    reason = detail.get("reason", "æœªæä¾›è¯„åˆ†åŸå› ")
                else:
                    score = detail if detail else 0
                    reason = "æœªæä¾›è¯„åˆ†åŸå› "

                markdown_parts.append(
                    f"| {config['name']} | {score} | {config['weight']}% | {reason} |"
                )

            markdown_parts.append("")

        # æ·»åŠ é—®é¢˜åˆ—è¡¨ï¼ˆæ–°æ ¼å¼ï¼‰
        if hasattr(review_result, 'issues') and review_result.issues:
            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„é—®é¢˜
            issues_by_severity = {
                'critical': [],
                'high': [],
                'medium': [],
                'low': []
            }
            
            for issue in review_result.issues:
                severity = issue.get('severity', 'medium')
                if severity in issues_by_severity:
                    issues_by_severity[severity].append(issue)
                else:
                    issues_by_severity['medium'].append(issue)
            
            markdown_parts.extend([
                "## ğŸ” å‘ç°çš„é—®é¢˜",
                "",
            ])
            
            # æŒ‰ä¸¥é‡ç¨‹åº¦é¡ºåºæ˜¾ç¤ºé—®é¢˜
            severity_order = ['critical', 'high', 'medium', 'low']
            severity_icons = {
                'critical': 'ğŸ”´',
                'high': 'ğŸŸ ', 
                'medium': 'ğŸŸ¡',
                'low': 'ğŸŸ¢'
            }
            severity_names = {
                'critical': 'ä¸¥é‡é—®é¢˜',
                'high': 'é‡è¦é—®é¢˜',
                'medium': 'ä¸€èˆ¬é—®é¢˜',
                'low': 'è½»å¾®é—®é¢˜'
            }
            
            for severity in severity_order:
                issues = issues_by_severity[severity]
                if not issues:
                    continue
                
                icon = severity_icons[severity]
                name = severity_names[severity]
                
                markdown_parts.extend([
                    f"### {icon} {name}",
                    "",
                ])
                
                for issue in issues:
                    issue_type = issue.get('type', 'info')
                    category = issue.get('category', '')
                    title = issue.get('title', '')
                    description = issue.get('description', '')
                    file_path = issue.get('file', '')
                    line_number = issue.get('line')
                    suggestion = issue.get('suggestion', '')
                    
                    # æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©å›¾æ ‡
                    type_icons = {
                        'error': 'âŒ',
                        'warning': 'âš ï¸',
                        'suggestion': 'ğŸ’¡',
                        'info': 'â„¹ï¸'
                    }
                    type_icon = type_icons.get(issue_type, 'ğŸ“')
                    
                    # æ„å»ºé—®é¢˜æè¿°
                    issue_text = f"#### {type_icon} {title}"
                    
                    # æ·»åŠ å…ƒä¿¡æ¯ï¼ˆä½¿ç”¨æ›´ç¾è§‚çš„æ ¼å¼ï¼‰
                    meta_parts = []
                    if category:
                        meta_parts.append(f"ğŸ·ï¸ **{category}**")
                    if file_path:
                        file_display = f"ğŸ“ `{file_path}`"
                        if line_number:
                            file_display += f":`{line_number}`"
                        meta_parts.append(file_display)
                    if issue_type != 'info':
                        type_names = {
                            'error': 'é”™è¯¯',
                            'warning': 'è­¦å‘Š', 
                            'suggestion': 'å»ºè®®',
                            'info': 'ä¿¡æ¯'
                        }
                        meta_parts.append(f"ğŸ”– {type_names.get(issue_type, issue_type)}")
                    
                    if meta_parts:
                        issue_text += f"\n\n> {' â€¢ '.join(meta_parts)}"
                    
                    # æ·»åŠ é—®é¢˜æè¿°ï¼ˆä½¿ç”¨å¼•ç”¨æ ¼å¼ï¼‰
                    issue_text += f"\n\n**é—®é¢˜æè¿°**:\n{description}"
                    
                    # æ·»åŠ å»ºè®®ï¼ˆä½¿ç”¨æ›´çªå‡ºçš„æ ¼å¼ï¼‰
                    if suggestion:
                        issue_text += f"\n\n**ğŸ’¡ æ”¹è¿›å»ºè®®**:\n{suggestion}"
                    
                    markdown_parts.append(issue_text)
                    markdown_parts.append("---")

        # æ·»åŠ å¤æ‚åº¦åˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
        if complexity_analysis:
            markdown_parts.extend([
                "## ğŸ” å¤æ‚åº¦åˆ†æ",
                "",
                f"**å¤æ‚åº¦ç­‰çº§**: {complexity_analysis.get('complexity_level', 'unknown')}",
                f"**æ€»å˜æ›´è¡Œæ•°**: {complexity_analysis.get('total_lines_changed', 0)}",
                f"**æ–°å¢è¡Œæ•°**: {complexity_analysis.get('additions', 0)}",
                f"**åˆ é™¤è¡Œæ•°**: {complexity_analysis.get('deletions', 0)}",
                "",
            ])

        # æ·»åŠ æäº¤ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if commit_stats:
            markdown_parts.extend([
                "## ğŸ“Š æäº¤ç»Ÿè®¡",
                "",
                f"**æ€»æäº¤æ•°**: {commit_stats.get('total_commits', 0)}",
                f"**ä¸»è¦è´¡çŒ®è€…**: {commit_stats.get('most_active_author', 'unknown')}",
                f"**æ—¶é—´è·¨åº¦**: {commit_stats.get('date_range', {}).get('span_days', 0)} å¤©",
                "",
            ])

        return "\n".join(markdown_parts)

    def _build_diff_from_gitx(self, diff_info, project: Project) -> str:
        """ä»gitxçš„DiffInfoæ„å»ºä»£ç å·®å¼‚æ–‡æœ¬"""
        # è·å–æ–‡ä»¶è¿‡æ»¤å™¨
        file_filter = self._get_file_filter_for_project(project)
        
        # è·å–æ‰€æœ‰æ–‡ä»¶è·¯å¾„
        all_file_paths = [file_change.file_path for file_change in diff_info.files]
        
        # è¿‡æ»¤æ–‡ä»¶
        filtered_files = file_filter.filter_file_list(all_file_paths)
        ignored_files = file_filter.get_ignored_files(all_file_paths)
        
        # è®°å½•è¿‡æ»¤ä¿¡æ¯
        if ignored_files:
            logger.info(f"è¿‡æ»¤äº† {len(ignored_files)} ä¸ªæ–‡ä»¶ï¼Œä¿ç•™ {len(filtered_files)} ä¸ªæ–‡ä»¶è¿›è¡Œå®¡æŸ¥")
            logger.debug(f"è¢«è¿‡æ»¤çš„æ–‡ä»¶: {ignored_files[:5]}{'...' if len(ignored_files) > 5 else ''}")
        
        diff_parts = []

        for file_change in diff_info.files:
            try:
                file_path = file_change.file_path
                
                # è·³è¿‡è¢«è¿‡æ»¤çš„æ–‡ä»¶
                if file_path not in filtered_files:
                    continue
                
                diff_parts.append(f"--- a/{file_path}")
                diff_parts.append(f"+++ b/{file_path}")

                # æ·»åŠ å˜æ›´ç±»å‹ä¿¡æ¯
                if file_change.change_type == 'A':
                    diff_parts.append("@@ -0,0 +1,1 @@")
                    diff_parts.append(f"+++ æ–°æ–‡ä»¶: {file_path}")
                elif file_change.change_type == 'D':
                    diff_parts.append("@@ -1,1 +0,0 @@")
                    diff_parts.append(f"--- åˆ é™¤æ–‡ä»¶: {file_path}")
                elif file_change.change_type == 'R':
                    diff_parts.append(f"@@ é‡å‘½å: {file_change.old_path} -> {file_path}")
                else:
                    # ä¿®æ”¹æ–‡ä»¶ï¼Œå°è¯•è·å–å…·ä½“å·®å¼‚
                    if self.git_service:
                        try:
                            file_diff = self.git_service.get_file_diff_content(
                                file_path,
                                diff_info.commit_sha,
                                diff_info.base_sha
                            )
                            diff_parts.append(file_diff)
                        except Exception:
                            diff_parts.append(f"@@ ä¿®æ”¹æ–‡ä»¶: {file_path} (+{file_change.additions}/-{file_change.deletions})")
                    else:
                        diff_parts.append(f"@@ ä¿®æ”¹æ–‡ä»¶: {file_path} (+{file_change.additions}/-{file_change.deletions})")

                diff_parts.append("")  # ç©ºè¡Œåˆ†éš”

            except Exception as e:
                logger.error(f"Error processing file change {file_change.file_path}: {str(e)}")
                continue

        return "\n".join(diff_parts)

    def _build_diff_text(self, changes: List[Any], project: Project) -> str:
        """æ„å»ºä»£ç å·®å¼‚æ–‡æœ¬"""
        # è·å–æ–‡ä»¶è¿‡æ»¤å™¨
        file_filter = self._get_file_filter_for_project(project)
        
        # è·å–æ‰€æœ‰æ–‡ä»¶è·¯å¾„
        all_file_paths = []
        for change in changes:
            file_path = change.new_path or change.old_path or "unknown"
            all_file_paths.append(file_path)
        
        # è¿‡æ»¤æ–‡ä»¶
        filtered_files = file_filter.filter_file_list(all_file_paths)
        ignored_files = file_filter.get_ignored_files(all_file_paths)
        
        # è®°å½•è¿‡æ»¤ä¿¡æ¯
        if ignored_files:
            logger.info(f"è¿‡æ»¤äº† {len(ignored_files)} ä¸ªæ–‡ä»¶ï¼Œä¿ç•™ {len(filtered_files)} ä¸ªæ–‡ä»¶è¿›è¡Œå®¡æŸ¥")
            logger.debug(f"è¢«è¿‡æ»¤çš„æ–‡ä»¶: {ignored_files[:5]}{'...' if len(ignored_files) > 5 else ''}")
        
        diff_parts = []

        for change in changes:
            try:
                file_path = change.new_path or change.old_path or "unknown"
                
                # è·³è¿‡è¢«è¿‡æ»¤çš„æ–‡ä»¶
                if file_path not in filtered_files:
                    continue
                
                diff_parts.append(f"--- a/{file_path}")
                diff_parts.append(f"+++ b/{file_path}")

                # ç¡®ä¿diffä¸ä¸ºç©º
                if hasattr(change, 'diff') and change.diff:
                    diff_parts.append(change.diff)
                else:
                    diff_parts.append("# No diff content available")

                diff_parts.append("")  # ç©ºè¡Œåˆ†éš”
            except Exception as e:
                logger.error(f"Error processing change: {str(e)}")
                continue

        return "\n".join(diff_parts)

    def _get_file_filter_for_project(self, project: Project):
        """
        è·å–é¡¹ç›®æ–‡ä»¶è¿‡æ»¤å™¨
        
        Args:
            project: é¡¹ç›®å¯¹è±¡
            
        Returns:
            æ–‡ä»¶è¿‡æ»¤å™¨å®ä¾‹
        """
        try:
            # ç®€åŒ–é€»è¾‘ï¼šåªä½¿ç”¨é€šç”¨è¿‡æ»¤å™¨å’ŒGoè¯­è¨€è¿‡æ»¤å™¨
            # å¯ä»¥æ ¹æ®éœ€è¦åœ¨è¿™é‡Œæ·»åŠ ç®€å•çš„åˆ¤æ–­é€»è¾‘
            # ç›®å‰é»˜è®¤ä½¿ç”¨é€šç”¨è¿‡æ»¤å™¨
            return get_file_filter("default")
                
        except Exception as e:
            logger.warning(f"è·å–é¡¹ç›®æ–‡ä»¶è¿‡æ»¤å™¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¿‡æ»¤å™¨: {str(e)}")
            return get_file_filter("default")
    
    def _get_go_file_filter(self):
        """
        è·å–Goè¯­è¨€æ–‡ä»¶è¿‡æ»¤å™¨
        
        Returns:
            Goè¯­è¨€æ–‡ä»¶è¿‡æ»¤å™¨å®ä¾‹
        """
        try:
            return get_file_filter("go")
        except Exception as e:
            logger.warning(f"è·å–Goæ–‡ä»¶è¿‡æ»¤å™¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¿‡æ»¤å™¨: {str(e)}")
            return get_file_filter("default")
    
    async def _create_token_usage_record(
            self,
            session: AsyncSession,
            review: CodeReview,
            review_result: Any
    ):
        """åˆ›å»ºTokenä½¿ç”¨è®°å½•"""
        try:
            # æ ¹æ®reviewer_typeè·å–æ¨¡å‹å®šä¹‰ï¼Œç„¶åæŸ¥æ‰¾å¯¹åº”çš„AIæ¨¡å‹
            model_def = get_model_definition(review.reviewer_type)
            if not model_def:
                logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹å®šä¹‰ {review.reviewer_type}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                model_def = get_model_definition('deepseek-v3.1')  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            
            # æ ¹æ®æ¨¡å‹åç§°æŸ¥æ‰¾æ•°æ®åº“ä¸­çš„æ¨¡å‹
            if model_def:
                # ä¼˜å…ˆæŸ¥æ‰¾æ´»è·ƒçš„æ¨¡å‹ï¼Œå¦‚æœæœ‰å¤šä¸ªåˆ™å–ç¬¬ä¸€ä¸ª
                result = await session.execute(
                    select(AIModel).where(
                        AIModel.model_name == model_def.name,
                        AIModel.is_active == True
                    ).order_by(AIModel.id)
                )
                ai_model = result.scalar_one_or_none()
                
                # å¦‚æœæ²¡æ‰¾åˆ°æ´»è·ƒçš„ï¼ŒæŸ¥æ‰¾æ‰€æœ‰æ¨¡å‹
                if not ai_model:
                    result = await session.execute(
                        select(AIModel).where(AIModel.model_name == model_def.name).order_by(AIModel.id)
                    )
                    ai_model = result.scalar_one_or_none()
            else:
                ai_model = None
            
            if not ai_model:
                # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼ˆID=1ï¼ŒDeepSeek v3.1ï¼‰
                logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹ {review.reviewer_type}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                result = await session.execute(
                    select(AIModel).where(AIModel.id == 1)  # å›ºå®šä½¿ç”¨DeepSeek v3.1ä½œä¸ºé»˜è®¤æ¨¡å‹
                )
                ai_model = result.scalar_one_or_none()
                
                if not ai_model:
                    logger.error("æœªæ‰¾åˆ°é»˜è®¤AIæ¨¡å‹ï¼ˆID=1ï¼‰ï¼Œè·³è¿‡Tokenä½¿ç”¨è®°å½•")
                    return
            
            # è®¡ç®—æˆæœ¬ï¼ˆå¦‚æœæœ‰å®šä»·ä¿¡æ¯ï¼‰
            cost = None
            if ai_model.pricing and review_result.tokens_used > 0:
                # ä½¿ç”¨æ–°çš„å®šä»·ç»“æ„è®¡ç®—æˆæœ¬
                pricing_info = ai_model.pricing
                
                # ç›´æ¥è°ƒç”¨æˆæœ¬
                direct_input_cost = 0
                if review_result.direct_token and review_result.direct_token > 0:
                    direct_input_cost = (review_result.direct_token / 1000000) * pricing_info.get("input_cost_per_1m", 0)
                
                # ç¼“å­˜è°ƒç”¨æˆæœ¬
                cache_input_cost = 0
                if review_result.cache_token and review_result.cache_token > 0:
                    cached_input_price = pricing_info.get("cached_input_cost_per_1m", pricing_info.get("input_cost_per_1m", 0))
                    cache_input_cost = (review_result.cache_token / 1000000) * cached_input_price
                
                # è¾“å‡ºæˆæœ¬
                output_cost = 0
                if review_result.completion_token and review_result.completion_token > 0:
                    output_cost = (review_result.completion_token / 1000000) * pricing_info.get("output_cost_per_1m", 0)
                
                cost = direct_input_cost + cache_input_cost + output_cost
            
            # åˆ›å»ºTokenUsageè®°å½•
            token_usage = TokenUsage(
                model_id=ai_model.id,
                review_id=review.id,
                usage_type="review",
                total_tokens=review_result.tokens_used or 0,
                prompt_tokens=review_result.prompt_token or 0,
                completion_tokens=review_result.completion_token or 0,
                direct_tokens=review_result.direct_token or 0,
                cache_tokens=review_result.cache_token or 0,
                cost=cost,
                request_duration=review_result.request_duration
            )
            
            session.add(token_usage)
            logger.info(f"åˆ›å»ºTokenä½¿ç”¨è®°å½•: æ¨¡å‹={ai_model.provider}/{ai_model.model_name}, "
                       f"æ€»token={token_usage.total_tokens}, æˆæœ¬=Â¥{cost or 0:.4f}")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºTokenä½¿ç”¨è®°å½•å¤±è´¥: {str(e)}")
            raise

    async def _create_failed_token_usage_record(
            self,
            session: AsyncSession,
            review: CodeReview,
            error: Exception
    ):
        """ä¸ºå¤±è´¥çš„å®¡æŸ¥åˆ›å»ºtokenä½¿ç”¨è®°å½•"""
        try:
            # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–tokenæ•°æ®
            token_data = self._extract_token_from_error(error)
            
            # æŸ¥æ‰¾å¯¹åº”çš„AIæ¨¡å‹
            ai_model = await self._find_ai_model_by_reviewer_type(session, review.reviewer_type)
            if not ai_model:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹
                try:
                    from app.services.ai.ai_service import ai_service
                    default_config = ai_service.get_model_config()
                    ai_model = await self._find_ai_model_by_name(session, default_config.provider.value, default_config.model_name)
                except Exception as e:
                    logger.warning(f"æ— æ³•æ‰¾åˆ°é»˜è®¤æ¨¡å‹: {str(e)}")
            
            if ai_model:
                # åˆ›å»ºTokenUsageè®°å½•ï¼Œå³ä½¿tokenä¸º0ä¹Ÿè¦è®°å½•
                token_usage = TokenUsage(
                    model_id=ai_model.id,
                    review_id=review.id,
                    usage_type="review",
                    total_tokens=token_data.get("tokens_used", 0),
                    prompt_tokens=token_data.get("prompt_token", 0),
                    completion_tokens=token_data.get("completion_token", 0),
                    direct_tokens=token_data.get("direct_token", 0),
                    cache_tokens=token_data.get("cache_token", 0),
                    cost=0,  # å¤±è´¥æ—¶æˆæœ¬ä¸º0
                    request_duration=token_data.get("request_duration", None)
                )
                
                session.add(token_usage)
                logger.info(f"ä¸ºå¤±è´¥çš„å®¡æŸ¥åˆ›å»ºäº†Tokenä½¿ç”¨è®°å½•: æ¨¡å‹={ai_model.provider}/{ai_model.model_name}, "
                           f"æ€»token={token_usage.total_tokens}")
            else:
                logger.warning(f"æ— æ³•ä¸ºå¤±è´¥çš„å®¡æŸ¥åˆ›å»ºtokenè®°å½•ï¼Œæœªæ‰¾åˆ°å¯¹åº”çš„AIæ¨¡å‹: {review.reviewer_type}")
                
        except Exception as e:
            logger.error(f"åˆ›å»ºå¤±è´¥å®¡æŸ¥çš„tokenè®°å½•æ—¶å‡ºé”™: {str(e)}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“ä¸»æµç¨‹

    def _extract_token_from_error(self, error: Exception) -> Dict[str, int]:
        """ä»é”™è¯¯ä¸­æå–tokenä¿¡æ¯"""
        token_data = {
            "tokens_used": 0,
            "prompt_token": 0,
            "completion_token": 0,
            "direct_token": 0,
            "cache_token": 0
        }
        
        try:
            # å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–tokenæ•°æ®
            error_str = str(error)
            
            # å¦‚æœé”™è¯¯ä¿¡æ¯ä¸­åŒ…å«tokenç›¸å…³ä¿¡æ¯ï¼Œå°è¯•æå–
            # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…çš„é”™è¯¯æ ¼å¼è¿›è¡Œè°ƒæ•´
            if "tokens_used" in error_str or "token" in error_str.lower():
                # ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼æå–ï¼ˆå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
                import re
                
                # æå–æ€»tokenæ•°
                total_match = re.search(r'tokens_used[:\s]*(\d+)', error_str, re.IGNORECASE)
                if total_match:
                    token_data["tokens_used"] = int(total_match.group(1))
                
                # æå–prompt tokenæ•°
                prompt_match = re.search(r'prompt_token[:\s]*(\d+)', error_str, re.IGNORECASE)
                if prompt_match:
                    token_data["prompt_token"] = int(prompt_match.group(1))
                
                # æå–completion tokenæ•°
                completion_match = re.search(r'completion_token[:\s]*(\d+)', error_str, re.IGNORECASE)
                if completion_match:
                    token_data["completion_token"] = int(completion_match.group(1))
                
                # æå–direct tokenæ•°
                direct_match = re.search(r'direct_token[:\s]*(\d+)', error_str, re.IGNORECASE)
                if direct_match:
                    token_data["direct_token"] = int(direct_match.group(1))
                
                # æå–cache tokenæ•°
                cache_match = re.search(r'cache_token[:\s]*(\d+)', error_str, re.IGNORECASE)
                if cache_match:
                    token_data["cache_token"] = int(cache_match.group(1))
                    
        except Exception as e:
            logger.debug(f"ä»é”™è¯¯ä¸­æå–tokenä¿¡æ¯å¤±è´¥: {str(e)}")
        
        return token_data

    async def _find_ai_model_by_reviewer_type(self, session: AsyncSession, reviewer_type: str):
        """æ ¹æ®reviewer_typeæŸ¥æ‰¾AIæ¨¡å‹"""
        try:
            if not reviewer_type:
                return None
                
            # reviewer_typeæ ¼å¼é€šå¸¸æ˜¯ "provider/model_name"
            if "/" in reviewer_type:
                provider, model_name = reviewer_type.split("/", 1)
            else:
                # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œå°è¯•ç›´æ¥åŒ¹é…æ¨¡å‹åç§°
                provider = None
                model_name = reviewer_type
            
            return await self._find_ai_model_by_name(session, provider, model_name)
            
        except Exception as e:
            logger.error(f"æ ¹æ®reviewer_typeæŸ¥æ‰¾AIæ¨¡å‹å¤±è´¥: {str(e)}")
            return None

    async def _find_ai_model_by_name(self, session: AsyncSession, provider: str, model_name: str):
        """æ ¹æ®providerå’Œmodel_nameæŸ¥æ‰¾AIæ¨¡å‹"""
        try:
            from app.models.ai_model import AIModel
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = []
            if provider:
                conditions.append(AIModel.provider == provider)
            if model_name:
                conditions.append(AIModel.model_name == model_name)
            
            if not conditions:
                return None
            
            stmt = select(AIModel).where(*conditions).order_by(AIModel.id)
            result = await session.execute(stmt)
            return result.scalar_one_or_none()
            
        except Exception as e:
            logger.error(f"æ ¹æ®åç§°æŸ¥æ‰¾AIæ¨¡å‹å¤±è´¥: {str(e)}")
            return None

    async def _create_review_comments(
            self,
            session: AsyncSession,
            review: CodeReview,
            review_result: Any
    ):
        """åˆ›å»ºå®¡æŸ¥è¯„è®º"""
        issues = review_result.issues

        for issue in issues:
            try:
                # å¤„ç†è¡Œå·ï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„æ•´æ•°
                line_number = self._parse_line_number(issue.get('line'))

                # è·å–è¯„è®ºå†…å®¹ - ä¼˜å…ˆä½¿ç”¨ descriptionï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ titleï¼Œæœ€åä½¿ç”¨ messageï¼ˆå‘åå…¼å®¹ï¼‰
                content = issue.get('description', '') or issue.get('title', '') or issue.get('message', '')
                
                # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡è¿™ä¸ªè¯„è®º
                if not content or content.strip() == '':
                    logger.warning(f"Skipping comment with empty content: {issue}")
                    continue

                # è°ƒè¯•æ—¥å¿—
                logger.debug(f"Creating comment: file={issue.get('file')}, line={issue.get('line')} -> {line_number}, type={issue.get('type', 'info')}, content_length={len(content)}")

                comment = ReviewComment(
                    review_id=review.id,
                    file_path=issue.get('file'),
                    line_number=line_number,
                    comment_type=issue.get('type', 'info'),
                    content=content
                )
                session.add(comment)
            except Exception as e:
                logger.error(f"Failed to create review comment: {str(e)}")
                logger.debug(f"Issue data: {issue}")
                continue

    def _parse_line_number(self, line_value) -> Optional[int]:
        """è§£æè¡Œå·ï¼Œç¡®ä¿è¿”å›æœ‰æ•ˆçš„æ•´æ•°æˆ–None"""
        if line_value is None:
            return None

        # å¦‚æœå·²ç»æ˜¯æ•´æ•°ï¼Œç›´æ¥è¿”å›
        if isinstance(line_value, int):
            return line_value if line_value > 0 else None

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢
        if isinstance(line_value, str):
            line_value = line_value.strip()

            # å¤„ç†ç‰¹æ®Šæƒ…å†µ
            if not line_value or line_value.lower() in ['å¤šä¸ª', 'multiple', 'n/a', 'null', 'none', 'æ— ']:
                return None

            # å°è¯•æå–æ•°å­—
            numbers = re.findall(r'\d+', line_value)
            if numbers:
                try:
                    return int(numbers[0])
                except ValueError:
                    return None

        return None

    async def _send_notifications(
            self,
            merge_request: MergeRequest,
            review: CodeReview,
            project: Project
    ):
        """å‘é€é€šçŸ¥"""
        try:
            # GitLabè¯„è®ºé€šçŸ¥
            if settings.NOTIFICATIONS_GITLAB_COMMENT_ENABLED:
                await self._send_gitlab_comment(merge_request, review, project)

            # å…¶ä»–é€šçŸ¥æ–¹å¼...

        except Exception as e:
            # é€šçŸ¥å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            logger.error(f"Failed to send notifications: {str(e)}")
            import traceback
            logger.debug(f"Traceback: {traceback.format_exc()}")

    async def _send_gitlab_comment(
            self,
            merge_request: MergeRequest,
            review: CodeReview,
            project: Project
    ):
        """å‘é€GitLabè¯„è®º"""
        if not review.review_content:
            return

        # æ„å»ºè¯„è®ºå†…å®¹
        score_emoji = "ğŸŸ¢" if review.score >= settings.REVIEW_SCORE_EXCELLENT else \
            "ğŸŸ¡" if review.score >= settings.REVIEW_SCORE_GOOD else "ğŸ”´"

        comment_body = f"""
{score_emoji} **AIä»£ç å®¡æŸ¥å®Œæˆ** - è¯„åˆ†: {review.score}

{review.review_content}

---
*From CodeSense-AI*
"""

        try:
            self.gitlab_client.create_merge_request_note(
                project.gitlab_id,
                merge_request.gitlab_id,
                comment_body
            )
        except Exception as e:
            logger.error(f"Failed to create GitLab comment: {str(e)}")
            import traceback
            logger.debug(f"Traceback: {traceback.format_exc()}")